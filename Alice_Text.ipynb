{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNqTKA2Dk2ISjookMXR+cvQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LUv2JEFmoETZ","executionInfo":{"status":"ok","timestamp":1717145334349,"user_tz":-420,"elapsed":2255,"user":{"displayName":"Trong Vu","userId":"14606860485809364123"}},"outputId":"0c64f474-d262-43ee-a9ce-233f4eb72f9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"90zg5frJ1v9N","executionInfo":{"status":"ok","timestamp":1717145392298,"user_tz":-420,"elapsed":11498,"user":{"displayName":"Trong Vu","userId":"14606860485809364123"}},"outputId":"bec1f718-4182-40df-e688-dcff637fc67c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.16.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.3.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.0)\n","Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.16.2)\n","Collecting keras>=3.0.0 (from tensorflow)\n","  Using cached keras-3.3.3-py3-none-any.whl (1.1 MB)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n","Installing collected packages: keras\n","  Attempting uninstall: keras\n","    Found existing installation: Keras 2.4.3\n","    Uninstalling Keras-2.4.3:\n","      Successfully uninstalled Keras-2.4.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-3.3.3\n"]}]},{"cell_type":"code","source":["#library\n","import numpy as np\n","import sys\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.models import Sequential\n","from keras.layers import LSTM,Dropout,Dense\n","from keras.callbacks import ModelCheckpoint\n","from keras.utils import to_categorical"],"metadata":{"id":"yqVPUo8qpPfV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Trong bài toán này, dữ liệu là cuốn truyện \"Alice ở xứ sở thần tiên\" được cung cấp dưới dạng ASCII, bài toán sẽ học cách sinh ra một kí tự dựa vào một chuỗi kí tự phía trước của nó. Từ việc sinh ra 1 kí tự , kết hợp ta sinh ra một đoạn văn bản từ những kí tự ban đầu."],"metadata":{"id":"QkgxT2HhsqdO"}},{"cell_type":"code","source":["#load_data\n","filename = \"/content/drive/MyDrive/Alice_Text_LSTM/wonderland.txt\"\n","#chuyển hết các dạng kí tự về kí tự viết thường\n","raw_text = open(filename, \"r\",encoding = \"utf-8 \").read()\n","raw_text = raw_text.lower()"],"metadata":{"id":"2cbVHT8ztsS_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chars = sorted(list(set(raw_text))) #tạo ra 1 list kí tự\n","char_to_int = dict((c,i) for i ,c in enumerate(chars)) #chuyển kí tự về số nguyên\n","int_to_char = dict((i,c) for  i ,c in enumerate(chars))"],"metadata":{"id":"I6Pls1tsvnSR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#tóm tắt lại việc xử lí data đầu vào\n","n_chars = len(raw_text)\n","n_vocab = len(chars)\n","print(\"Total characters:\" , n_chars)\n","print(\"Total Vobab:\", n_vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CtQLqFquw3Vp","executionInfo":{"status":"ok","timestamp":1717145410901,"user_tz":-420,"elapsed":330,"user":{"displayName":"Trong Vu","userId":"14606860485809364123"}},"outputId":"d85697e1-cca2-4dfd-ed65-8ce8327e6afa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total characters: 144512\n","Total Vobab: 45\n"]}]},{"cell_type":"markdown","source":["Có thể thấy rằng chúng ta có gần 150,000 kí tự khi đã chuyển đổi về kí tự viết thường. chỉ có 45 kí tự phân biệt, nhiều hơn so với bản chuẩn chữ cái tiếng anh chỉ có 26 chữ cái."],"metadata":{"id":"Dcu02pyAxXyE"}},{"cell_type":"code","source":["#chia cuốn sách thành các chuỗi kí tự có độ dài 100\n","seq_length = 100 #đầu vào của mạng sẽ là 100 kí tự\n","dataX = []\n","dataY = []\n","for i in range(0,n_chars-seq_length,1):\n","    seq_in = raw_text[i:i+seq_length]\n","    seq_out = raw_text[i+seq_length]\n","    dataX.append([char_to_int[char] for char in seq_in])\n","    dataY.append(char_to_int[seq_out])\n","n_patterns = len(dataX)\n","print(\"Total Patterns :\" ,n_patterns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6UzSSVcgxXZZ","executionInfo":{"status":"ok","timestamp":1717145414470,"user_tz":-420,"elapsed":1770,"user":{"displayName":"Trong Vu","userId":"14606860485809364123"}},"outputId":"d298dd61-21b2-43b6-a4ea-4b9afbb27c05"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Patterns : 144412\n"]}]},{"cell_type":"code","source":["X = np.reshape(dataX ,(n_patterns , seq_length,1))\n","#normalize\n","X = X /float(n_vocab)\n","#one_hot_encoding\n","y = to_categorical(dataY)"],"metadata":{"id":"bztt3_89y3Cx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install keras==2.4.3"],"metadata":{"id":"ZoL5-G5c1cvk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tạo nên 1 mô hình LSTM\n","model = Sequential()\n","model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(256))\n","model.add(Dropout(0.2))\n","model.add(Dense(y.shape[1], activation='softmax'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XZyg-_94ztC5","executionInfo":{"status":"ok","timestamp":1717145423296,"user_tz":-420,"elapsed":356,"user":{"displayName":"Trong Vu","userId":"14606860485809364123"}},"outputId":"82999ace-c885-4e80-d588-0eb3287f345b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]}]},{"source":["# tạo nên các file checkpoint lưu việc training\n","filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.keras\"\n","checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n","callbacks_list = [checkpoint]"],"cell_type":"code","metadata":{"id":"LiH2PS5s6efP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss = \"categorical_crossentropy\",optimizer = \"adam\")\n","model.fit(X,y,epochs = 20,batch_size = 128 , callbacks = callbacks_list)"],"metadata":{"id":"9VLR7esD6wwJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load lại file trọng số đã lưu của mạng\n","filename = \"weights-improvement-47-1.2219-bigger.hdf5\"\n","model.load_weights(filename)\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\n","# lựa chọn seed ngẫu nhiên để tạo test\n","start = np.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","print(\"Seed:\")\n","print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n","# generate characters\n","for i in range(1000):\n","\tx = np.reshape(pattern, (1, len(pattern), 1))\n","\tx = x / float(n_vocab)\n","\tprediction = model.predict(x, verbose=0)\n","\tindex = np.argmax(prediction)\n","\tresult = int_to_char[index]\n","\tseq_in = [int_to_char[value] for value in pattern]\n","\tsys.stdout.write(result)\n","\tpattern.append(index)\n","\tpattern = pattern[1:len(pattern)]\n","print(\"\\nDone.\")"],"metadata":{"id":"mS2bk61BGLc1"},"execution_count":null,"outputs":[]}]}